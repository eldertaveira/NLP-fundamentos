{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d9H5142rtP2C"
      },
      "outputs": [],
      "source": [
        "# Importando bibliotecas\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from gensim import corpora, models\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5-LdmxYuEZa",
        "outputId": "0a7ab6c2-231f-4038-c884-b2822dbfbfe8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Texto de exemplo\n",
        "texto = \"\"\"\n",
        "Processamento de Linguagem Natural (PLN) é uma área da inteligência artificial que se concentra na interação entre\n",
        "computadores e linguagem humana. A tokenização é o primeiro passo no pré-processamento de texto, onde o texto é dividido\n",
        "em tokens. Bag of Words (BoW) é uma técnica que representa um documento como um conjunto de palavras, sem levar em conta\n",
        "a ordem. A biblioteca Gensim é comumente usada para modelagem de tópicos, enquanto o TF-IDF destaca a importância das\n",
        "palavras em um documento.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qAMwIonatcaK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenização\n",
        "tokens = word_tokenize(texto.lower())  # Converte para minúsculas para evitar diferenciação entre maiúsculas e minúsculas\n",
        "print(\"Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7ax1tpIt2Oi",
        "outputId": "5dffc94c-fb43-46b1-8f8c-49458619dee8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['processamento', 'de', 'linguagem', 'natural', '(', 'pln', ')', 'é', 'uma', 'área', 'da', 'inteligência', 'artificial', 'que', 'se', 'concentra', 'na', 'interação', 'entre', 'computadores', 'e', 'linguagem', 'humana', '.', 'a', 'tokenização', 'é', 'o', 'primeiro', 'passo', 'no', 'pré-processamento', 'de', 'texto', ',', 'onde', 'o', 'texto', 'é', 'dividido', 'em', 'tokens', '.', 'bag', 'of', 'words', '(', 'bow', ')', 'é', 'uma', 'técnica', 'que', 'representa', 'um', 'documento', 'como', 'um', 'conjunto', 'de', 'palavras', ',', 'sem', 'levar', 'em', 'conta', 'a', 'ordem', '.', 'a', 'biblioteca', 'gensim', 'é', 'comumente', 'usada', 'para', 'modelagem', 'de', 'tópicos', ',', 'enquanto', 'o', 'tf-idf', 'destaca', 'a', 'importância', 'das', 'palavras', 'em', 'um', 'documento', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYRjfNNYuU81",
        "outputId": "84cbcb3d-71ea-4f5b-f1c1-f3c19b724efd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remoção de stop words\n",
        "stop_words = set(stopwords.words(\"portuguese\"))\n",
        "filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "print(\"Tokens filtrados:\", filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBnfUP2CuMjJ",
        "outputId": "354957ff-941f-473b-8f03-61423627b9b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens filtrados: ['processamento', 'linguagem', 'natural', 'pln', 'área', 'inteligência', 'artificial', 'concentra', 'interação', 'computadores', 'linguagem', 'humana', 'tokenização', 'primeiro', 'passo', 'texto', 'onde', 'texto', 'dividido', 'tokens', 'bag', 'of', 'words', 'bow', 'técnica', 'representa', 'documento', 'conjunto', 'palavras', 'levar', 'conta', 'ordem', 'biblioteca', 'gensim', 'comumente', 'usada', 'modelagem', 'tópicos', 'enquanto', 'destaca', 'importância', 'palavras', 'documento']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag of Words\n",
        "freq_dist = FreqDist(filtered_tokens)\n",
        "print(\"Bag of Words:\")\n",
        "pprint(freq_dist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwDNtMMNug-u",
        "outputId": "40a9318a-8c7d-4186-c4dd-40181aaa9d4a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag of Words:\n",
            "FreqDist({'linguagem': 2, 'texto': 2, 'documento': 2, 'palavras': 2, 'processamento': 1, 'natural': 1, 'pln': 1, 'área': 1, 'inteligência': 1, 'artificial': 1, ...})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gensim - Modelo de Tópicos (LDA)\n",
        "# Preparando o corpus\n",
        "dictionary = corpora.Dictionary([filtered_tokens])\n",
        "corpus = [dictionary.doc2bow(filtered_tokens)]"
      ],
      "metadata": {
        "id": "9LNXPsEjuwfP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treinando o modelo\n",
        "lda_model = models.LdaModel(corpus, num_topics=1, id2word=dictionary, passes=10)\n",
        "print(\"\\nModelo de Tópicos (LDA):\")\n",
        "pprint(lda_model.print_topics())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFc0dSfLu85b",
        "outputId": "cdcaab79-3a5c-49bb-9df6-4e62245fb7e6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Modelo de Tópicos (LDA):\n",
            "[(0,\n",
            "  '0.037*\"documento\" + 0.037*\"linguagem\" + 0.037*\"texto\" + 0.037*\"palavras\" + '\n",
            "  '0.024*\"tokenização\" + 0.024*\"passo\" + 0.024*\"pln\" + 0.024*\"ordem\" + '\n",
            "  '0.024*\"representa\" + 0.024*\"onde\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform([texto])\n",
        "print(\"\\nTF-IDF Matrix:\")\n",
        "print(tfidf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFAGYu9xvF2w",
        "outputId": "c640346a-d591-40df-f33a-b942a2403153"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF Matrix:\n",
            "  (0, 11)\t0.09622504486493763\n",
            "  (0, 22)\t0.09622504486493763\n",
            "  (0, 13)\t0.09622504486493763\n",
            "  (0, 21)\t0.09622504486493763\n",
            "  (0, 46)\t0.09622504486493763\n",
            "  (0, 17)\t0.09622504486493763\n",
            "  (0, 50)\t0.09622504486493763\n",
            "  (0, 27)\t0.09622504486493763\n",
            "  (0, 35)\t0.09622504486493763\n",
            "  (0, 53)\t0.09622504486493763\n",
            "  (0, 6)\t0.09622504486493763\n",
            "  (0, 19)\t0.09622504486493763\n",
            "  (0, 2)\t0.09622504486493763\n",
            "  (0, 33)\t0.09622504486493763\n",
            "  (0, 9)\t0.09622504486493763\n",
            "  (0, 25)\t0.09622504486493763\n",
            "  (0, 44)\t0.09622504486493763\n",
            "  (0, 34)\t0.19245008972987526\n",
            "  (0, 8)\t0.09622504486493763\n",
            "  (0, 4)\t0.09622504486493763\n",
            "  (0, 15)\t0.19245008972987526\n",
            "  (0, 51)\t0.28867513459481287\n",
            "  (0, 42)\t0.09622504486493763\n",
            "  (0, 49)\t0.09622504486493763\n",
            "  (0, 3)\t0.09622504486493763\n",
            "  :\t:\n",
            "  (0, 32)\t0.09622504486493763\n",
            "  (0, 45)\t0.19245008972987526\n",
            "  (0, 40)\t0.09622504486493763\n",
            "  (0, 30)\t0.09622504486493763\n",
            "  (0, 36)\t0.09622504486493763\n",
            "  (0, 38)\t0.09622504486493763\n",
            "  (0, 47)\t0.09622504486493763\n",
            "  (0, 20)\t0.09622504486493763\n",
            "  (0, 5)\t0.09622504486493763\n",
            "  (0, 18)\t0.09622504486493763\n",
            "  (0, 24)\t0.09622504486493763\n",
            "  (0, 28)\t0.09622504486493763\n",
            "  (0, 7)\t0.09622504486493763\n",
            "  (0, 43)\t0.09622504486493763\n",
            "  (0, 41)\t0.19245008972987526\n",
            "  (0, 0)\t0.09622504486493763\n",
            "  (0, 23)\t0.09622504486493763\n",
            "  (0, 10)\t0.09622504486493763\n",
            "  (0, 55)\t0.09622504486493763\n",
            "  (0, 52)\t0.19245008972987526\n",
            "  (0, 37)\t0.09622504486493763\n",
            "  (0, 29)\t0.09622504486493763\n",
            "  (0, 26)\t0.19245008972987526\n",
            "  (0, 12)\t0.3849001794597505\n",
            "  (0, 39)\t0.19245008972987526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtendo o vocabulário do vetorizador\n",
        "vocabulario = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "# Obtendo a palavra correspondente à posição (0, 2)\n",
        "palavra = vocabulario[2]\n",
        "\n",
        "# Imprimindo a palavra correspondente\n",
        "print(\"A palavra correspondente à posição (0, 2) é:\", palavra)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ryLN7xrvzaO",
        "outputId": "ec30b712-3653-48c2-e026-ab45f8ba3fee"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A palavra correspondente à posição (0, 2) é: biblioteca\n"
          ]
        }
      ]
    }
  ]
}